# 当前配置文件的版本号，请不要修改该值。
conf.version = 1
# 是用来生成pid文件用 , 多个配置文件可以配多个id
id = redis-shake
# log file，日志文件，不配置将打印到stdout (e.g. /var/log/redis-shake.log )
log.file =
# log level: "none", "error", "warn", "info", "debug". default is "info".
log.level = info
# pid path，进程文件存储地址（e.g. /var/run/)，不配置将默认输出到执行下面,
# 注意这个是目录，真正的pid是`{pid_path}/{id}.pid`
pid_path = 

# pprof port.
system_profile = 9310
# restful port，查看metric端口, -1表示不启用，如果是`restore`模式，只有设置为-1才会在完成RDB恢复后退出，否则会一直block。
# restore模式请一定要设置成
http_profile = -1
# 启动多少个并发线程同步一个RDB文件。
parallel = 32


#######################################################
# 上面其实我都没动 , 这里开始就动的比较多了         #########
#######################################################

#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# 输入源 , 输入域有两种方式 1:redis库 2:指定rdb文件(decode或者restore模式专用使用)          @
#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

# 源端redis的类型，支持standalone，sentinel，cluster和proxy四种模式，注意：目前proxy只用于rump模式。
source.type = cluster
# 源地址 , 多个用分号(;)隔开
# ***注意*** : 必须是所有的master或者slave节点,不能混合配置,提前去服务器上用cluster info看一下
source.address = 172.18.0.232:7001;172.18.0.233:7000;172.18.0.233:7001
# 密码
source.password_raw = 123456
source.auth_type = auth
source.tls_enable = false
# 如果是decode或者restore，这个参数表示读取的rdb文件。支持输入列表，例如：rdb.0;rdb.1;rdb.2 ,依次恢复
source.rdb.input = /home/redishome/redis-shake-v2.0.2/wxiot.rdb
source.rdb.parallel = 0
# ucloud集群版的rdb文件添加了slot前缀，进行特判剥离: ucloud_cluster。
source.rdb.special_cloud = 

#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# 输入目标库, 配置全权参考输入,基本一样            @
#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
target.type = standalone
target.address = 172.18.0.122:6379
target.password_raw = 12345678
target.auth_type = auth
target.db = -1
target.tls_enable = false
# 如果是decode或者dump，这个参数表示输出的rdb前缀.
# 比如输入有3个db，那么dump分别是: ${output_rdb}.0, ${output_rdb}.1, ${output_rdb}.2
target.rdb.output = /home/redishome/redis-shake-v2.0.2/wxiot.rdb
# 特殊情况可配置redis版本
target.version =


# 当源目的有重复key的策略 rewrite:源端覆盖目的端; none:一旦发生进程直接退出; ignore: 保留目的端key，忽略源端的同步key;
# 该值在rump模式下没有用。
key_exists = ignore

#######################################################
# 下面其实也没动                              #########
#######################################################
fake_time =
# 指定的db被通过，比如0;5;10将会使db0, db5, db10通过, 其他的被过滤
filter.db.whitelist =
# 指定的db被过滤，比如0;5;10将会使db0, db5, db10过滤，其他的被通过
filter.db.blacklist =
# 支持按前缀过滤key，只让指定前缀的key通过，分号分隔。比如指定abc，将会通过abc, abc1, abcxxx
filter.key.whitelist =
# 支持按前缀过滤key，不让指定前缀的key通过，分号分隔。比如指定abc，将会阻塞abc, abc1, abcxxx
filter.key.blacklist =
# 指定过滤slot，只让指定的slot通过
filter.slot =
# 控制不让lua脚本通过，true表示不通过
filter.lua = false
# 正常key如果不大，那么都是直接调用restore写入到目的端，如果key对应的value字节超过了给定
# 的值，那么会分批依次一个一个写入。如果目的端是Codis，这个需要置为1，具体原因请查看FAQ。
# 如果目的端大版本小于源端，也建议设置为1。
big_key_threshold = 524288000
# 是否启用metric
metric = true
# 是否将metric打印到log中
metric.print_log = false
# 发送缓存的字节长度，超过这个阈值将会强行刷缓存发送
sender.size = 104857600
# 发送缓存的报文个数，超过这个阈值将会强行刷缓存发送，对于目的端是cluster的情况，这个值
# 的调大将会占用部分内存。
sender.count = 4095
# 用于metric统计时延的队列
sender.delay_channel_size = 65535
# TCP keep-alive保活参数，单位秒，0表示不启用。
keep_alive = 0
# 每次scan的个数，不配置则默认100.
scan.key_number = 50
# 有些版本具有特殊的格式，与普通的scan命令有所不同，我们进行了特殊的适配。目前支持腾讯云的集群版"tencent_cluster"
# 和阿里云的集群版"aliyun_cluster"，注释主从版不需要配置，只针对集群版。
scan.special_cloud =
# 有些云版本，既不支持sync/psync，也不支持scan，我们支持从文件中进行读取所有key列表并进行抓取：一行一个key。
scan.key_file =
# e.g., qps = 1000 means pass 1000 keys per second. default is 500,000(0 means default)
qps = 200000
# 断点续传开关
resume_from_break_point = false
replace_hash_tag = false